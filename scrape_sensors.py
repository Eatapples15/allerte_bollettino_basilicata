import requests
from bs4 import BeautifulSoup
import json
import datetime
import re
import sys

# CONFIGURAZIONE URL
BASE_URL = "https://centrofunzionale.regione.basilicata.it/it/sensoriTempoReale.php"
JSON_FILENAME = "dati_sensori.json"

SENSORI = {
Â  Â  "idrometria": {"code": "I", "label": "Idrometri", "unit": "m", "threshold": 2.0},
Â  Â  "pluviometria": {"code": "P", "label": "Pluviometri", "unit": "mm", "threshold": 40.0},
Â  Â  "anemometria": {"code": "VV", "label": "Anemometri", "unit": "m/s", "threshold": 15.0},
Â  Â  "termometria": {"code": "T", "label": "Termometri", "unit": "Â°C", "threshold": 38.0},
Â  Â  "nivometria": {"code": "N", "label": "Nivometri", "unit": "cm", "threshold": 5.0}
}

FAKE_HEADERS = {
Â  Â  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
}

def clean_text(text):
Â  Â  if not text: return ""
Â  Â  return re.sub(r'\s+', ' ', text.replace("\xa0", " ")).strip()

def parse_value(val_str):
Â  Â  try:
Â  Â  Â  Â  if not val_str: return None
Â  Â  Â  Â  # Rimuovi unitÃ  di misura (es. "mm", "m") e spazi
Â  Â  Â  Â  clean = re.sub(r'[^\d\.,\-]', '', val_str)
Â  Â  Â  Â  # Sostituisci virgola con punto
Â  Â  Â  Â  clean = clean.replace(",", ".")
Â  Â  Â  Â  return float(clean)
Â  Â  except:
Â  Â  Â  Â  return None

def scrape_sensor_bs4(sensor_key, config):
Â  Â  url = f"{BASE_URL}?st={config['code']}"
Â  Â  print(f"\n--- Scraping {config['label']} ({url}) ---")
Â  Â Â 
Â  Â  data_list = []
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  r = requests.get(url, headers=FAKE_HEADERS, timeout=30)
Â  Â  Â  Â  soup = BeautifulSoup(r.text, 'html.parser')
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Cerca la tabella con id "rilevazioni"
Â  Â  Â  Â  table = soup.find("table", {"id": "rilevazioni"})
Â  Â  Â  Â  if not table:
Â  Â  Â  Â  Â  Â  print("âš ï¸ Tabella 'rilevazioni' non trovata.")
Â  Â  Â  Â  Â  Â  return []

Â  Â  Â  Â  # Cerca il body della tabella
Â  Â  Â  Â  tbody = table.find("tbody")
Â  Â  Â  Â  if not tbody:
Â  Â  Â  Â  Â  Â  print("âš ï¸ Tbody non trovato.")
Â  Â  Â  Â  Â  Â  return []

Â  Â  Â  Â  rows = tbody.find_all("tr")
Â  Â  Â  Â  print(f"ğŸ“Š Righe trovate: {len(rows)}")

Â  Â  Â  Â  for row in rows:
Â  Â  Â  Â  Â  Â  cols = row.find_all("td")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # La struttura standard ha circa 6 colonne
Â  Â  Â  Â  Â  Â  if len(cols) < 5: continue
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # 1. Stazione e ID (Colonna 0)
Â  Â  Â  Â  Â  Â  col_stazione = cols[0]
Â  Â  Â  Â  Â  Â  nome_stazione = clean_text(col_stazione.text)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  link = col_stazione.find("a")
Â  Â  Â  Â  Â  Â  station_id = ""
Â  Â  Â  Â  Â  Â  if link and 'href' in link.attrs:
Â  Â  Â  Â  Â  Â  Â  Â  match = re.search(r'id=(\d+)', link['href'])
Â  Â  Â  Â  Â  Â  Â  Â  if match: station_id = match.group(1)

Â  Â  Â  Â  Â  Â  # 2. Valore (Colonna 3 - indice 3 perchÃ© si parte da 0)
Â  Â  Â  Â  Â  Â  # Spesso Ã¨ dentro un <strong> e un <a>
Â  Â  Â  Â  Â  Â  valore_raw = clean_text(cols[3].text)
Â  Â  Â  Â  Â  Â  valore_num = parse_value(valore_raw)

Â  Â  Â  Â  Â  Â  # 3. Data/Ora (Colonna 4)
Â  Â  Â  Â  Â  Â  data_ora = clean_text(cols[4].text)

Â  Â  Â  Â  Â  Â  # Filtri validitÃ 
Â  Â  Â  Â  Â  Â  if not nome_stazione or valore_num is None: continue

Â  Â  Â  Â  Â  Â  # Se l'orario Ã¨ solo ore (es "12:00"), aggiungi la data di oggi
Â  Â  Â  Â  Â  Â  if len(data_ora) <= 5:
Â  Â  Â  Â  Â  Â  Â  Â  today = datetime.datetime.now().strftime("%d/%m/%Y")
Â  Â  Â  Â  Â  Â  Â  Â  data_ora = f"{today} {data_ora}"

Â  Â  Â  Â  Â  Â  status = "normal"
Â  Â  Â  Â  Â  Â  if abs(valore_num) >= config['threshold']: status = "alert"
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  data_list.append({
Â  Â  Â  Â  Â  Â  Â  Â  "id": station_id,
Â  Â  Â  Â  Â  Â  Â  Â  "nome": nome_stazione,
Â  Â  Â  Â  Â  Â  Â  Â  "data": data_ora,
Â  Â  Â  Â  Â  Â  Â  Â  "valore": valore_num,
Â  Â  Â  Â  Â  Â  Â  Â  "status": status
Â  Â  Â  Â  Â  Â  })

Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Errore: {e}")

Â  Â  print(f"âœ… Record estratti: {len(data_list)}")
Â  Â  return data_list

def main():
Â  Â  final_data = {
        "ultimo_aggiornamento": datetime.datetime.now().strftime("%d/%m/%Y %H:%M"),
        "sensori": {}
    }

    total_records = 0
    for key, config in SENSORI.items():
        readings = scrape_sensor_bs4(key, config)
        final_data["sensori"][key] = {
            "meta": config,
            "dati": readings
        }
        total_records += len(readings)

    try:
        with open(JSON_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=4, ensure_ascii=False)
        print(f"\nğŸ’¾ Salvataggio completato ({total_records} sensori totali)")
    except Exception as e:
        print(f"âŒ Errore scrittura file: {e}")

if __name__ == "__main__":
    main()
