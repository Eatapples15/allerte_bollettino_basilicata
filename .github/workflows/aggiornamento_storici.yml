name: Aggiornamento Dati Storici (Cumulati)

on:
  schedule:
    # Esegue ogni 2 ore (es. 00:00, 02:00, 04:00, etc.)
    - cron: '0 */2 * * *'
  
  # Permette l'avvio manuale dal tab "Actions"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-history:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout del codice
        uses: actions/checkout@v3

      - name: Imposta Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Installazione Librerie
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 selenium webdriver-manager

      - name: Esecuzione Scraping Storico
        # Questo lancia lo script dedicato ai dettagli delle stazioni
        run: python scrape_history.py

      - name: Commit e Push dei Dati Storici
        run: |
          git config --global user.name "Storico Bot"
          git config --global user.email "bot-storico@users.noreply.github.com"
          
          # Aggiungiamo il file JSON generato dallo script scrape_history.py
          git add dati_storici.json
          
          # Esegue il commit solo se ci sono variazioni effettive
          git diff --quiet && git diff --staged --quiet || (git commit -m "Aggiornamento Dati Storici (Cumulati 1h-24h)" && git push)
